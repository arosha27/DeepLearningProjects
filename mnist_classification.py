# -*- coding: utf-8 -*-
"""mnist-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kQ_GCP5YWKZyVTmYjjE2NWfUqjmQxfr3
"""

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense , Flatten

(X_train , y_train) ,(X_test , y_test) = keras.datasets.mnist.load_data()

X_train.shape , X_test.shape , y_train , y_test

#in order to look at the first image in the training data :
import matplotlib.pyplot as plt
plt.imshow(X_train[0] , cmap = "grey")

# now we have to build a neural network which can learn the pixels values of the images and then decide which pixel values are pointing to which image iin the data .

"""- one thing to be noted is that in every image the pixel values in the arrays are in between 0 and 255 . we need to make them between 0 and 1
- Its very important that our numbers should be in the similar range for the better training of the neural network, for better and fast convergence.
- to make the values range from 0 to 255 , we will devide them each value with 255
- 0 / 255 = 0 , 255/255 = 1
"""

X_train = X_train/255
X_test = X_test / 255

X_train[0]

#creating an ANN
model = Sequential()

#the model required 1D array of pixel values (784) as an input . and we have 2D array (28,28)
#flatten layer for converting higher dimension arrays to 1d
model.add(Flatten(input_shape=(28 , 28)))

#adding our first dense layer - ist hidden layer
model.add(Dense(128 , activation = "relu"))
model.add(Dense(30 , activation = "relu"))

#adding output layer
model.add(Dense(10 , activation = "softmax"))

model.summary()

#compile and train the model to understand the pixels pattern
model.compile(loss= "sparse_categorical_crossentropy", optimizer="Adam" , metrics=["accuracy"])

#sparse_categorical crossentropy loss function does not require the additional on hot encoding unlike the categorical_crossentropy

#model traing
history = model.fit(X_train , y_train , epochs = 10 , validation_split = 0.2)

#prediction on testing data
y_prob = model.predict(X_test)
y_pred = y_prob.argmax(axis=1)

#evaluation by finding the accuracy score
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_pred , y_test)
accuracy

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])

X_test

# predictions on some sample images
plt.imshow(X_test[0] , cmap = "grey") , X_test[0].shape

import numpy as np
import matplotlib.pyplot as plt

# Select 10 random indices from X_test
random_indices = np.random.choice(len(X_test), size=10)

# Create a figure
plt.figure(figsize=(15,5))

# Loop through the random indices
for i, idx in enumerate(random_indices):
    # Predict the label
    pred = model.predict(X_test[idx].reshape(1, 28, 28)).argmax(axis=1)

    # Plot the image
    plt.subplot(2, 5, i + 1)
    plt.imshow(X_test[idx], cmap='gray')
    plt.title(f"Predicted: {pred}")
    plt.axis('off')

plt.tight_layout()
plt.show()

